// Assets/RealtimeVoiceChatController.cs
using UnityEngine;
using UnityEngine.UI;
using System.Collections.Generic;

public enum AudioOutputMode
{
    OpenAIDirect,        // OpenAI ì˜¤ë””ì˜¤ ì§ì ‘ ì¬ìƒ
    RVCStreaming,        // OpenAI ì˜¤ë””ì˜¤ â†’ RVC ìŠ¤íŠ¸ë¦¬ë° ë³€í™˜
    TraditionalTTS,      // ê¸°ì¡´ TTS (VOICEVOX + RVC)
    TextStreamingTTS     // OpenAI í…ìŠ¤íŠ¸ â†’ VOICEVOX + RVC ìŠ¤íŠ¸ë¦¬ë° (ê°€ì¥ ë¹ ë¦„)
}

public class RealtimeVoiceChatController : MonoBehaviour
{
    [Header("Component References")]
    public OpenAIRealtimeClient realtimeClient;
    public TTSStreamClient ttsClient;
    public RVCStreamClient rvcClient;
    public TTSTextStreamClient ttsTextStreamClient; // ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° í´ë¼ì´ì–¸íŠ¸

    [Header("UI References")]
    public Text statusText;
    public Text userText;
    public Text assistantText;
    public Button recordButton;
    public Button clearHistoryButton;

    [Header("Chat Settings")]
    public bool autoPlayResponse = true;
    public bool showConversationInUI = true;
    public AudioOutputMode audioOutputMode = AudioOutputMode.TextStreamingTTS; // ê¸°ë³¸ê°’ ë³€ê²½

    [Header("Visual Feedback")]
    public Color recordingColor = Color.red;
    public Color processingColor = Color.yellow;
    public Color readyColor = Color.white;
    public Color errorColor = Color.red;
    public Color connectedColor = Color.green;

    [Header("Debug")]
    public bool enableDebugLog = true;

    // Audio playback for OpenAI audio response
    private AudioSource _audioSource;
    private Queue<byte[]> _audioQueue;
    private bool _isPlayingAudio = false;

    private void Start()
    {
        InitializeComponents();
        SetupEventHandlers();
        UpdateUI("Connecting to OpenAI Realtime...", processingColor);
    }

    private void InitializeComponents()
    {
        // ì»´í¬ë„ŒíŠ¸ ìë™ ê²€ìƒ‰
        if (realtimeClient == null) realtimeClient = FindObjectOfType<OpenAIRealtimeClient>();
        if (ttsClient == null) ttsClient = FindObjectOfType<TTSStreamClient>();
        if (rvcClient == null) rvcClient = FindObjectOfType<RVCStreamClient>();

        // ì»´í¬ë„ŒíŠ¸ê°€ ì—†ìœ¼ë©´ ìë™ ì¶”ê°€
        if (realtimeClient == null) realtimeClient = gameObject.AddComponent<OpenAIRealtimeClient>();
        if (rvcClient == null) rvcClient = gameObject.AddComponent<RVCStreamClient>();

        // AudioSource ì„¤ì • (OpenAI ì˜¤ë””ì˜¤ìš©)
        _audioSource = GetComponent<AudioSource>();
        if (_audioSource == null) _audioSource = gameObject.AddComponent<AudioSource>();

        _audioQueue = new Queue<byte[]>();

        // UI ë²„íŠ¼ ì„¤ì •
        if (recordButton) recordButton.onClick.AddListener(ToggleRecording);
        if (clearHistoryButton) clearHistoryButton.onClick.AddListener(ClearConversationHistory);
    }

    private void SetupEventHandlers()
    {
        if (realtimeClient)
        {
            // ì—°ê²° ì´ë²¤íŠ¸
            realtimeClient.OnConnected += OnRealtimeConnected;
            realtimeClient.OnDisconnected += OnRealtimeDisconnected;
            realtimeClient.OnError += OnRealtimeError;

            // ë…¹ìŒ ì´ë²¤íŠ¸
            realtimeClient.OnRecordingStarted += OnRecordingStarted;
            realtimeClient.OnRecordingStopped += OnRecordingStopped;

            // ì‘ë‹µ ì´ë²¤íŠ¸
            realtimeClient.OnTranscriptionReceived += OnTranscriptionReceived;
            realtimeClient.OnTextResponseReceived += OnTextResponseReceived;
            realtimeClient.OnTextDelta += OnTextDelta; // í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°
            realtimeClient.OnAudioResponseReceived += OnAudioResponseReceived;
            realtimeClient.OnResponseDone += OnResponseDone;
        }

        if (rvcClient)
        {
            // RVC í´ë¼ì´ì–¸íŠ¸ ì´ë²¤íŠ¸
            rvcClient.OnConnected += OnRVCConnected;
            rvcClient.OnDisconnected += OnRVCDisconnected;
            rvcClient.OnError += OnRVCError;
        }
    }

    // Realtime ì—°ê²° ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë“¤
    private void OnRealtimeConnected()
    {
        UpdateUI("Ready - Press Space to start voice chat", connectedColor);
        UpdateRecordButton();
        if (enableDebugLog) Debug.Log("[RealtimeChat] Connected to OpenAI Realtime API");
    }

    private void OnRealtimeDisconnected()
    {
        UpdateUI("Disconnected from OpenAI Realtime", errorColor);
        UpdateRecordButton();
        if (enableDebugLog) Debug.Log("[RealtimeChat] Disconnected from OpenAI Realtime API");
    }

    private void OnRealtimeError(string error)
    {
        UpdateUI($"Realtime error: {error}", errorColor);
        UpdateRecordButton();
        Debug.LogError($"[RealtimeChat] Error: {error}");

        // 3ì´ˆ í›„ ìƒíƒœ ë¦¬ì…‹
        Invoke(nameof(ResetToReady), 3f);
    }

    // ë…¹ìŒ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë“¤
    private void OnRecordingStarted()
    {
        UpdateUI("ğŸ¤ Recording... (Release Space to stop)", recordingColor);
        UpdateRecordButton();
        if (enableDebugLog) Debug.Log("[RealtimeChat] Recording started");
    }

    private void OnRecordingStopped()
    {
        UpdateUI("ğŸ”„ Processing speech...", processingColor);
        UpdateRecordButton();
        if (enableDebugLog) Debug.Log("[RealtimeChat] Recording stopped");
    }

    // ì‘ë‹µ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë“¤
    private void OnTranscriptionReceived(string transcript)
    {
        if (showConversationInUI && userText)
        {
            userText.text = $"You: {transcript}";
        }

        if (enableDebugLog) Debug.Log($"[RealtimeChat] User said: {transcript}");
    }

    private string _textBuffer = "";

    private void OnTextDelta(string textDelta)
    {
        _textBuffer += textDelta;

        // UI ì—…ë°ì´íŠ¸
        if (showConversationInUI && assistantText)
        {
            assistantText.text = $"Assistant: {_textBuffer}";
        }

        // TextStreamingTTS ëª¨ë“œì—ì„œ í…ìŠ¤íŠ¸ ì²­í¬ ì „ì†¡
        if (audioOutputMode == AudioOutputMode.TextStreamingTTS && autoPlayResponse && ttsTextStreamClient && ttsTextStreamClient.IsConnected)
        {
            _ = ttsTextStreamClient.SendTextChunk(textDelta);
        }
    }

    private void OnTextResponseReceived(string response)
    {
        if (showConversationInUI && assistantText)
        {
            assistantText.text = $"Assistant: {response}";
        }

        if (enableDebugLog) Debug.Log($"[RealtimeChat] Assistant responded: {response}");

        // Traditional TTS ëª¨ë“œì—ì„œë§Œ ê¸°ì¡´ TTS ì‚¬ìš©
        if (audioOutputMode == AudioOutputMode.TraditionalTTS && autoPlayResponse && ttsClient)
        {
            UpdateUI("ğŸ”Š Playing response...", processingColor);
            ttsClient.Speak(response);
        }
    }

    private void OnAudioResponseReceived(byte[] audioData)
    {
        if (!autoPlayResponse) return;

        switch (audioOutputMode)
        {
            case AudioOutputMode.OpenAIDirect:
                // OpenAI ì˜¤ë””ì˜¤ ì§ì ‘ ì¬ìƒ
                _audioQueue.Enqueue(audioData);
                if (!_isPlayingAudio)
                {
                    UpdateUI("ğŸ”Š Playing response...", processingColor);
                    StartCoroutine(PlayAudioQueue());
                }
                break;

            case AudioOutputMode.RVCStreaming:
                // OpenAI ì˜¤ë””ì˜¤ë¥¼ RVC ì„œë²„ë¡œ ìŠ¤íŠ¸ë¦¬ë°
                if (rvcClient && rvcClient.IsConnected)
                {
                    UpdateUI("ğŸ”Š Converting voice...", processingColor);
                    _ = rvcClient.SendAudioData(audioData);
                }
                break;

            case AudioOutputMode.TraditionalTTS:
                // í…ìŠ¤íŠ¸ ì‘ë‹µë§Œ ì‚¬ìš©, ì˜¤ë””ì˜¤ëŠ” ë¬´ì‹œ
                break;
        }
    }

    private void OnResponseDone()
    {
        if (enableDebugLog) Debug.Log("[RealtimeChat] Response done");

        // RVC ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì¸ ê²½ìš° end ì‹ í˜¸ ì „ì†¡
        if (audioOutputMode == AudioOutputMode.RVCStreaming && rvcClient && rvcClient.IsConnected)
        {
            _ = rvcClient.SendEndSignal();
        }

        // TextStreamingTTS ëª¨ë“œì¸ ê²½ìš° end ì‹ í˜¸ ì „ì†¡
        if (audioOutputMode == AudioOutputMode.TextStreamingTTS && ttsTextStreamClient && ttsTextStreamClient.IsConnected)
        {
            _ = ttsTextStreamClient.SendEndSignal();
            _textBuffer = ""; // ë²„í¼ ì´ˆê¸°í™”
        }
    }

    // RVC ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë“¤
    private void OnRVCConnected()
    {
        if (enableDebugLog) Debug.Log("[RealtimeChat] RVC server connected");
    }

    private void OnRVCDisconnected()
    {
        if (enableDebugLog) Debug.Log("[RealtimeChat] RVC server disconnected");
    }

    private void OnRVCError(string error)
    {
        Debug.LogError($"[RealtimeChat] RVC error: {error}");
    }

    private System.Collections.IEnumerator PlayAudioQueue()
    {
        _isPlayingAudio = true;

        while (_audioQueue.Count > 0)
        {
            var audioData = _audioQueue.Dequeue();

            // PCM16 ë°ì´í„°ë¥¼ AudioClipìœ¼ë¡œ ë³€í™˜
            var audioClip = ConvertPCM16ToAudioClip(audioData, realtimeClient.sampleRate);

            if (audioClip != null)
            {
                _audioSource.clip = audioClip;
                _audioSource.Play();

                // ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
                yield return new WaitForSeconds(audioClip.length);

                // AudioClip ì •ë¦¬
                DestroyImmediate(audioClip);
            }

            yield return null;
        }

        _isPlayingAudio = false;
        UpdateUI("Ready - Press Space for next question", readyColor);
        UpdateRecordButton();
    }

    private AudioClip ConvertPCM16ToAudioClip(byte[] pcm16Data, int sampleRate)
    {
        if (pcm16Data == null || pcm16Data.Length == 0) return null;

        // PCM16 ë°”ì´íŠ¸ë¥¼ float ë°°ì—´ë¡œ ë³€í™˜
        int sampleCount = pcm16Data.Length / 2;
        float[] samples = new float[sampleCount];

        for (int i = 0; i < sampleCount; i++)
        {
            short sample = (short)(pcm16Data[i * 2] | (pcm16Data[i * 2 + 1] << 8));
            samples[i] = sample / 32768f;
        }

        // AudioClip ìƒì„±
        var clip = AudioClip.Create("RealtimeAudio", sampleCount, 1, sampleRate, false);
        clip.SetData(samples, 0);

        return clip;
    }

    // UI ì—…ë°ì´íŠ¸ ë©”ì„œë“œë“¤
    private void UpdateUI(string message, Color? color = null)
    {
        if (statusText)
        {
            statusText.text = message;
            if (color.HasValue) statusText.color = color.Value;
        }
    }

    private void UpdateRecordButton()
    {
        if (recordButton)
        {
            var buttonText = recordButton.GetComponentInChildren<Text>();
            if (buttonText)
            {
                if (!realtimeClient.IsConnected)
                {
                    buttonText.text = "Disconnected";
                    recordButton.interactable = false;
                }
                else if (realtimeClient.IsRecording)
                {
                    buttonText.text = "Stop Recording";
                    recordButton.interactable = true;
                }
                else
                {
                    buttonText.text = "Start Recording";
                    recordButton.interactable = true;
                }
            }
        }
    }

    private void ResetToReady()
    {
        if (realtimeClient.IsConnected)
        {
            UpdateUI("Ready - Press Space for voice chat", readyColor);
        }
        else
        {
            UpdateUI("Disconnected from OpenAI Realtime", errorColor);
        }
        UpdateRecordButton();
    }

    // ê³µê°œ ë©”ì„œë“œë“¤
    public void ToggleRecording()
    {
        if (!realtimeClient.IsConnected) return;

        if (realtimeClient.IsRecording)
        {
            realtimeClient.StopRecording();
        }
        else
        {
            realtimeClient.StartRecording();
        }
    }

    public void ClearConversationHistory()
    {
        // OpenAI Realtime APIëŠ” ì„¸ì…˜ ê¸°ë°˜ì´ë¯€ë¡œ ìƒˆ ì„¸ì…˜ìœ¼ë¡œ ì¬ì‹œì‘
        if (realtimeClient && realtimeClient.IsConnected)
        {
            if (userText) userText.text = "";
            if (assistantText) assistantText.text = "";
            UpdateUI("Conversation cleared - Reconnecting...", processingColor);

            // ì¬ì—°ê²°ë¡œ ìƒˆ ì„¸ì…˜ ì‹œì‘
            _ = RestartSession();

            if (enableDebugLog) Debug.Log("[RealtimeChat] Conversation cleared - restarting session");
        }
    }

    private async System.Threading.Tasks.Task RestartSession()
    {
        await realtimeClient.Disconnect();
        await System.Threading.Tasks.Task.Delay(1000); // 1ì´ˆ ëŒ€ê¸°
        // realtimeClientëŠ” Start()ì—ì„œ ìë™ìœ¼ë¡œ ì¬ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤
    }

    public void SetAutoPlayResponse(bool enabled)
    {
        autoPlayResponse = enabled;
        if (enableDebugLog) Debug.Log($"[RealtimeChat] Auto play response: {enabled}");
    }

    public void SetAudioOutputMode(AudioOutputMode mode)
    {
        audioOutputMode = mode;
        if (enableDebugLog) Debug.Log($"[RealtimeChat] Audio output mode: {mode}");
    }

    public void SetInstructions(string newInstructions)
    {
        if (realtimeClient)
        {
            realtimeClient.SetInstructions(newInstructions);
            if (enableDebugLog) Debug.Log($"[RealtimeChat] Instructions updated: {newInstructions}");
        }
    }

    public void SetVoice(string newVoice)
    {
        if (realtimeClient)
        {
            realtimeClient.SetVoice(newVoice);
            if (enableDebugLog) Debug.Log($"[RealtimeChat] Voice updated: {newVoice}");
        }
    }

    // í˜„ì¬ ìƒíƒœ ì •ë³´
    public bool IsRecording() => realtimeClient && realtimeClient.IsRecording;
    public bool IsConnected() => realtimeClient && realtimeClient.IsConnected;

    private void OnDestroy()
    {
        // ì´ë²¤íŠ¸ í•´ì œ
        if (realtimeClient)
        {
            realtimeClient.OnConnected -= OnRealtimeConnected;
            realtimeClient.OnDisconnected -= OnRealtimeDisconnected;
            realtimeClient.OnError -= OnRealtimeError;
            realtimeClient.OnRecordingStarted -= OnRecordingStarted;
            realtimeClient.OnRecordingStopped -= OnRecordingStopped;
            realtimeClient.OnTranscriptionReceived -= OnTranscriptionReceived;
            realtimeClient.OnTextResponseReceived -= OnTextResponseReceived;
            realtimeClient.OnTextDelta -= OnTextDelta;
            realtimeClient.OnAudioResponseReceived -= OnAudioResponseReceived;
            realtimeClient.OnResponseDone -= OnResponseDone;
        }

        if (rvcClient)
        {
            rvcClient.OnConnected -= OnRVCConnected;
            rvcClient.OnDisconnected -= OnRVCDisconnected;
            rvcClient.OnError -= OnRVCError;
        }

        // ì˜¤ë””ì˜¤ ì •ë¦¬
        while (_audioQueue != null && _audioQueue.Count > 0)
        {
            _audioQueue.Dequeue();
        }
    }
}